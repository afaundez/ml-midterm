\documentclass[letterpaper, conference]{IEEEtran}

\usepackage{amsmath}
\usepackage{mathabx}
\DeclareMathOperator*{\argmax}{argmax}

\usepackage{pgfplots}
\pgfplotsset{compat=1.5.1}

\usepackage{titlesec}
\titlespacing*{\subsection}{0pt}{1.1\baselineskip}{\baselineskip}
\setlength{\parindent}{2em}
\setlength{\parskip}{0.7em}

\usepackage{url}

\begin{document}

\title{Midterm Report \\
  \large Machine Learning}

\author{
  \IEEEauthorblockN{Alvaro Faundez}
  \IEEEauthorblockA{
    \textit{Master in Data Science, first year}\\
    \textit{CUNY Graduate Center}\\
    \textit{alvaro@faundez.net}
  }
}

\maketitle

\begin{abstract}

This report details the implementation of a discrete Bayesian classifier. The classifier requirements are a dataset and an economic gain matrix for input. The process calculates the class, measurement conditional, and class conditional probabilities from the dataset, all needed for the Bayes theorem. It outputs the Bayes rule, the confusion matrix and the expected gain matrix associated to the input used. After training  and predicting steps are complete, small perturbations were introduced in the measurement conditional probabilities of every misclassification, obtaining an improvement, as expected, in the expected gain (after recalculating all the classifier's outputs). The experiments included using the dataset split into equally sized  training and test sets and also using K-fold cross validation. The dataset were created using synthetic probabilities distribution. A series of results are detailed in the appendix.

\end{abstract}

\section{Introduction}

Given a set of classifications, a measurement space and a dataset, the classifier uses the Bayes theorem to compute the conditional probabilities needed to perform a classification. Using an economic gain matrix, the classifier can optimized by maximizing the expected gain obtained through the Bayes decision rule.

The definition and implementation include:

\begin{itemize}
  \item Classification and measurement dimensions definitions, including pseudo-random probabilities and cumulative distribution functions
  \item Space definition and linear addresses
  \item Class prior and conditional probabilities
  \item Classifier optimization using an economic gain matrix
  \item Dataset definition and generation of pseudo-random synthetic data
  \item Experimentation framework with two types of cross-validation.
\end{itemize}

The classifier is tested by adding small perturbation to the class conditional, increasing the expected gain. The increase was tested using are training/test and k-folds cross-validation.

This report details the theory of a discrete Bayesian classifier used to implement the classifier. A technical overview explain the implementation from scratch in the Ruby language, and the results of the experiments executed.

\section{Theory}

The discrete Bayesian classifier is a popular predictive classifier broadly used in Machine Learning, based in the Bayes Theorem [\ref{eq:bayes-theorem}].

\begin{equation}\label{eq:bayes-theorem}
  P(A \mid B) = \frac{P(B \mid A)\mathbin{}P(A)}{P(B)}
\end{equation}

In our case, given a set $C$ of $K$ discrete classifications [\ref{eq:classes-set}] and a discrete measurement space $D$, result of the cartesian product of $N$ measurements $L$ [\ref{eq:measurement-space}], the objective is assigning a classification $c \in C$ to any measurement $d \in D$.

\begin{equation}\label{eq:classes-set}
C = \{0,\, \dots,\, c_{K - 1}\}
\end{equation}

\begin{equation} \label{eq:measurement-set}
\begin{aligned}
  L_n &= \{0,\, \dots,\, M_{n} - 1\} \\
  \vert L_n \vert &= M_n
\end{aligned}
\end{equation}

\begin{equation} \label{eq:measurement-space}
D = \bigtimes_{n=1}^{N} L_n
\end{equation}

For the classification, we need the following inputs:
\begin{itemize}
  \item the discrete classification cardinality, $K$
  \item the cardinalities of each discrete measurement, $\vert L_n \vert,\, n \in N$
  \item an economic gain matrix, $E$
  \item a dataset with $Z$ measurements, and $Z$ classifications. Alternatively, the class and class conditional probabilities could be used instead a dataset.
\end{itemize}

The Economic Gain matrix, $E$, is a squared matrix that defines the gain (or cost) of making the right or wrong classifications [\ref{eq:economic-gain-matrix}]. A column represents the assigned class, and a row represents the true class, then every element $E_{i, j} = e(c_i, c_j)$ represent the gain or cost of assigning the class $c_j$ when the true class was $c_i$. The expected gain usually is positive for every correct classification, and non-positive for every other case. The identity matrix is an example of an economic gain matrix.

\begin{equation}\label{eq:economic-gain-matrix}
  E = \begin{pmatrix}
    e(c_1,\,c_1) & \cdots & e(c_1,\,c_K) \\
      \vdots   & \ddots &    \vdots   \\
    e(c_K,\,c_1) & \cdots & c(c_K,\,c_K)
  \end{pmatrix}
\end{equation}

Our goal, is to maximize the Expected Gain of the classifier, $E$.

\begin{equation}
  E[e, f] = \sum_{c \in C} \sum_{d \in D}f_d(c)\mathbin{}e(c, c)\mathbin{}P(c \mid d)
\end{equation}

A critical step in the construction of the classifier is the building of the Bayes decision rule. It determines which class maximize the Expected Gain for every measurement $d$ [\ref{eq:bayes-argmax}]. This way, the Bayes decision rule for a measurement, $f_d$, will assign 1 to the class that maximize the Expected Gain, and 0 otherwise [\ref{eq:bayes-rule}]

\begin{equation}\label{eq:bayes-argmax}
  \argmax_{c_k \in C} \sum_{j = 1}^{K} e(c_j, c_k)\mathbin{}P(c_j, d)
\end{equation}

\begin{equation}\label{eq:bayes-rule}
  f_d(c_j) = \left\{
  \begin{array}{lr}
  1 & j = k\\
  0 & j \neq k
  \end{array}\right\}
\end{equation}

To obtain $f_d$, it is necessary to calculate the posterior probability of assign a class $c$ to measurement $d$, $P(c \mid d)$, using the prior class probability $P(c)$ and the probability of the measurement given the class $P(d \mid c)$ [\ref{eq:bayes-theorem-proportional}]. $P(c)$ and $P(d \mid c)$ can be calculated from the dataset or can be received as an input.


\begin{equation} \label{eq:bayes-theorem-proportional}
P(c \mid d) \mathbin{\propto} P(d \mid c)\mathbin{}P(c)
\end{equation}

\section{Technical}

\subsection{Requirements}

To run the code, a Unix environment with Ruby 2.6+ is necessary. The code is available on GitHub at \url{https://github.com/afaundez/ml-midterm}.

To test the command and check the available options run

\begin{verbatim}
  $ ./midterm --help
\end{verbatim}

\subsection{options}

For the purpose of testing, the following parameters are available for configuration

\begin{itemize}
    \item-s, --seed [INT]                 Pseudo-random seed, an integer. Default: nil
    \item-c, --classes [INT]              Class cardinality, an integer. Default 2
    \item-m, --measurements [INT]         Measurements size, an integer. Default 5
    \item    --measurement-min-cardinality [INT]
                                     Measurement Min Cardinality, an integer. Default 3
    \item    --measurement-max-cardinality [INT]
                                     Measurement Max Cardinality, an integer. Default 6
    \item    --sample-size [INT]          Sample size, an integer. Default to 10 times the  space addresses size.
    \item-i, --iterations [INT]           Iterations, an integer. Default 2
    \item-d, --delta [FLOAT]              Delta for conditionals improvement, a float. Default: 0.01
    \item    --no-overlap                 Generate classes based on measurements
    \item    --uniform                    Use uniform distribution on all dimensions
\end{itemize}

\subsection{Runtime}

\subsubsection{Build}

During the build, three significant abstractions are used: Dimension, Space, and DataSet.

The Dimension abstraction is meant to store the cardinality, probabilities distribution function, and cumulative distribution function of a single measurement or class. A dimension does not store values, but it can be used to generate random values using the distribution functions. A Dimension is defined by:

\begin{itemize}
  \item size
  \item pdf, generated based on the size
  \item cdf, generate based on the pdf
  \item distribution, whether to use random or uniform distribution
\end{itemize}

The Space abstraction stores the single class dimension \ref{classes}, the collection of measurements dimensions \ref{dimensions}, and the class conditional probabilities. Since the Space knows all the dimensions specifications, it is in charge of translating and measurement into a linear address and vice-versa. A Space is defined by:

\begin{itemize}
\item class\_dimension, a Dimension instance
\item measurements\_dimensions, a collection of Dimension instances
\item likelihoods, random pdfs
\end{itemize}

The DataSet abstraction is in charge of generating and storing measurement values and the associated class, all bounded to a specific space. Since it has access to the data and space, it is in charge of the training and improving the class conditional probabilities, determining the Bayes Decision Rule, generating the Confusion Matrix, and calculating the Expected Gain. It is relevant that at the time of creating, the prior class probabilities are calculated and stored in the DataSet. A DataSet is defined by:

\begin{itemize}
\item size
\item space, a Space instance
\item samples, a collection of collections of measurements
\item class\_outcomes, counter of classes for prior class probabilities calculation
\item overlap, whether to assign classes with overlap
\end{itemize}

The Economic Gain Matrix is generated in this step. Even though it is a method, currently, the only matrix available is the identity matrix.

\subsubsection{Training}

Once a set of DataSet is created, the test DataSet is picked and left isolated, and the rest is used as train DataSet.

The training process consists of two steps: using the training set and an economic gain matrix, the training outputs the Bayes decision rule, and the expected gain. Then, using the Bayes decision rule, it generates the confusion matrix.


At the end of this process, the Space associated with the DataSet will store the measurement conditional probabilities $P(c \mid d)$ targeted in \ref{eq:bayes}.

\subsection{Optimization}

Now that the space is trained and the measurement conditional probabilities have been processed, using the delta as input, the dataset can improve the class conditional probabilities using the test DataSet. For each mismatched classification, the corresponding class conditional probability is incremented by the delta input, and the measurement probabilities are normalized to 1. This process yields an updated Space and accuracy obtained.

\section{Experimental Results}

Even though it is not a strict test, it is good to do a sanity check with a dummy case: one feature, one value measurement. It is expected to have an expected gain of 1.0 and an accuracy of 1.0.

Running

\begin{verbatim}
  bin/midterm --classes 1 --measurements 1
\end{verbatim}

yields, as expected,

\begin{verbatim}
Economic Gain Matrix
+---+
| 1 |
+---+

Train 0.
  Expected Gain: 1.0
  Confusion Matrix Trace: 1.0
  Accuracy: 1.0
Confusion Matrix
+-----+
| 1.0 |
+-----+

Test
  Expected Gain: 1.0
  Confusion Matrix Trace: 1.0
  Accuracy: 1.0
\end{verbatim}


The next step is to check the results using. Let us use two classes, five values measurements, and ten training sets, and start setting the seed number in order to have replicable experiments.

\subsection{First results}

\begin{verbatim}
  bin/midterm --classes 2 --measurements 5 \
    --iterations 10 --seed 1234
\end{verbatim}

The expected gain and accuracy do not seem to be correct

\begin{figure}[hbt]
  \label{fig:10-training-2-classes}
  \input{figures/10-training-2-classes}
  \caption{}
\end{figure}

Incrementing the training iterations to 100 does not make real improvements; it keeps going up and down.

\begin{figure}[hbt]
  \label{fig:100-training-2-classes}
  \input{figures/100-training-2-classes}
  \caption{}
\end{figure}

To identify the reason of these results, two options were added to the application, one to control the overlap in the class assignment to a measurement and how the probability distribution is generated.

\subsection{Probability distributions}

Since the method used to generate the probability distribution function for a dimension does not generate even probabilities for each value in the dimension, a parameter $--uniform$ was added to revert this and generate uniform distribution for the classes and measurement. The hypothesis was that by generating numbers evenly, the results would easier to understand.

Now, repeating the previous commands with the new parameter:

\begin{verbatim}
  bin/midterm --classes 2 --measurements 5 \
    --iterations 10 --seed 1234 \
    --uniform
\end{verbatim}

\begin{figure}[hbt]
  \label{fig:10-training-2-classes-uniform}
  \input{figures/10-training-2-classes-uniform}
  \caption{}
\end{figure}

The expected gain does not seem to be improving, but the accuracy is set around $0.5$. It could be a sign that accuracy is bouncing between that particular number because now each class has the same probability of being assign to a measurement. Using 100 training iterations, the result is similar.

\begin{figure}[hbt]
  \label{fig:100-training-2-classes-uniform}
  \input{figures/100-training-2-classes-uniform}
  \caption{}
\end{figure}

Checking with 3 classes, the accuracy bounce around $0.33$ as expected:

\begin{figure}[hbt]
  \label{fig:10-training-3-classes-uniform}
  \input{figures/10-training-3-classes-uniform}
  \caption{}
\end{figure}

\subsection{Class overlapping}

To understand if the accuracies shown in the previous steps are determined by the number of classes and the overlapping caused by an assignation independent from the measurements, it was added to the program the option to avoid the overlap and assign a class based on the norm of the measurement vector. This is an arbitrary assignment chosen just by the simplicity and certainty of the assignment's uniqueness.

using the new parameter

\begin{verbatim}
  bin/midterm --classes 2 --measurements 5 \
    --iterations 10 --seed 1234 \
    --no-overlap
\end{verbatim}

\begin{figure}[hbt]
  \label{fig:10-training-2-classes-no-overlapping}
  \input{figures/10-training-2-classes-no-overlapping}
  \caption{}
\end{figure}

Now the expected gain is considerably higher, and trying with 100 iterations stays close to 1.0.

\begin{figure}[hbt]
  \label{fig:100-training-2-classes-no-overlapping}
  \input{figures/100-training-2-classes-no-overlapping}
  \caption{}
\end{figure}

\section{Conclusions}

This report shows a Bayes classifier written from scratch in Ruby without any scientific library, following the theory and instructions provided during the Machine Learning class.

The program includes definitions and abstractions for Dimension, Space, and DataSet that can be configured with optional parameters through the command line to create classes, measurement, and training sets.

The initial results were not the one expected, showing low and bouncing expected gains and accuracy. As a way to explain these behaviors, two paths were developed

\begin{itemize}
  \item First, create the dimensions for classes and measurements using uniform probability distribution functions, expecting more recognizable numbers. The method worked, and it allowed us to determine that the accuracy was inversely proportional to the classes' cardinality.
  \item Then, with the conclusion from the previous step, it was introduced an option to assign a class to a specific measurement without overlapping. The norm of the measurement vector was the method used, and it produced a considerable impact on the expected gain and accuracy, reaching values over $0.99$ in both parameters.
\end{itemize}

Although some aspects of the value could have been explained with the overlapping of classes, it remains inconclusive why the expected gain and accuracy are not reaching 1.0 or why it does not stop bouncing.

\begin{thebibliography}{2}

\bibitem{discrete-bayes}
Robert M. Haralick,
\textit{Discrete Bayes Pattern Recognition}
\\\texttt{\url{http://haralick.org/ML/discrete_bayes.pdf}}

\bibitem{midterm-project}
Robert M. Haralick,
\textit{Midterm Project}
\\\texttt{\url{http://haralick.org/ML/midterm_project.pdf}}

\end{thebibliography}

\end{document}
